{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000000"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from scipy.stats import pearsonr\n",
    "from scipy import stats\n",
    "csv.field_size_limit(10000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exp 1a-c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the experiment for analysis here\n",
    "exp_ID = \"1c\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contains log normalized reaction time data \n",
    "filename = \"Exp\" + exp_ID + \"_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather subject labels\n",
    "subject_labels = []\n",
    "\n",
    "with open(filename, mode='r') as csv_file:\n",
    "    csv_reader = csv.DictReader(csv_file)\n",
    "    \n",
    "    for row in csv_reader:\n",
    "        if row['subject'] not in subject_labels:\n",
    "            subject_labels.append(row['subject'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_data = {}\n",
    "\n",
    "current_subjects = subject_labels\n",
    "# current_ID_identifiers = subjects_ID_identifiers[exp_ID]\n",
    "\n",
    "for subject in current_subjects:\n",
    "    \n",
    "    exp_data[subject] = {\"speeded\": {}, \"inference\": {}, \"direct\": {}}\n",
    "\n",
    "    for i in range(48):\n",
    "        exp_data[subject][\"speeded\"][i+1] = {}\n",
    "    \n",
    "    for i in range(12):\n",
    "        exp_data[subject][\"inference\"][i+1] = {}\n",
    "\n",
    "    if exp_ID == \"1c\":\n",
    "        for i in range(24):\n",
    "            exp_data[subject][\"direct\"][i+1] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(filename, mode='r') as csv_file:\n",
    "    csv_reader = csv.DictReader(csv_file)\n",
    "    \n",
    "    for row in csv_reader:\n",
    "        \n",
    "        if row['task_type'] == 'speeded_recognition':\n",
    "                \n",
    "            exp_data[row['subject']][\"speeded\"][int(row['trial_number'])] = {\"subject\": row['subject'],\n",
    "                                                                    \"experiment\": exp_ID,\n",
    "                                                                    \"task_type\": 'speeded_recognition',\n",
    "                                                                    \"trial_number\": row['trial_number'],\n",
    "                                                                    \"target_pair_type\": row['target_pair_type'],\n",
    "                                                                    \"target_pair_condition\": row['target_pair_condition'],\n",
    "                                                                    \"target_triad_index\": row['target_triad_index'],\n",
    "                                                                    \"response_correct\": row['response_correct'],\n",
    "                                                                    \"response_time\": row['response_time']}\n",
    "        elif row['task_type'] == 'explicit_inference':\n",
    "            \n",
    "            exp_data[row['subject']][\"inference\"][int(row['trial_number'])] = {\"subject\": row['subject'],\n",
    "                                                                        \"experiment\": exp_ID,\n",
    "                                                                        \"task_type\": 'explicit_inference',\n",
    "                                                                        \"trial_number\": row['trial_number'],\n",
    "                                                                        \"target_pair_type\": row['target_pair_type'],\n",
    "                                                                        \"target_pair_condition\": row['target_pair_condition'],\n",
    "                                                                        \"target_triad_index\": row['target_triad_index'],\n",
    "                                                                        \"response_correct\": row['response_correct'],\n",
    "                                                                        \"response_time\": row['response_time']}\n",
    "            \n",
    "        elif exp_ID == '1c' and row['task_type'] == 'explicit_direct':\n",
    "            \n",
    "            exp_data[row['subject']][\"direct\"][int(row['trial_number'])] = {\"subject\": row['subject'],\n",
    "                                                                \"experiment\": exp_ID,\n",
    "                                                                \"task_type\": 'explicit_direct',\n",
    "                                                                \"trial_number\": row['trial_number'],\n",
    "                                                                \"target_pair_type\": row['target_pair_type'],\n",
    "                                                                \"target_pair_condition\": row['target_pair_condition'],\n",
    "                                                                \"target_triad_index\": row['target_triad_index'],\n",
    "                                                                \"response_correct\": row['response_correct'],\n",
    "                                                                \"response_time\": row['response_time']}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify two variables to compare\n",
    "\n",
    "# Options: speeded, inference, direct\n",
    "v1_experiment = 'speeded'\n",
    "v2_experiment = 'speeded'\n",
    "\n",
    "v1_pair_type = 'AC'\n",
    "v2_pair_type = 'foil'\n",
    "\n",
    "v1_pair_condition = 'intermixed'\n",
    "v2_pair_condition = 'intermixed'\n",
    "\n",
    "# Options: RT, accuracy\n",
    "v1_type = 'RT'\n",
    "v2_type = 'RT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1_v2_differences = []\n",
    "\n",
    "for subject in exp_data:\n",
    "    \n",
    "    v1_correct = []\n",
    "    v1_all = []\n",
    "    for trial_number in exp_data[subject][v1_experiment]:\n",
    "        trial_data = exp_data[subject][v1_experiment][trial_number]\n",
    "        if trial_data['target_pair_type'] == v1_pair_type and trial_data['target_pair_condition'] == v1_pair_condition:\n",
    "            if trial_data['response_correct'] == 'correct':\n",
    "                if v1_type == 'RT':\n",
    "                    v1_correct.append(float(trial_data['response_time']))\n",
    "                if v1_type == 'accuracy':\n",
    "                    v1_correct.append(1.0)\n",
    "                    v1_all.append(1.0)\n",
    "            else:\n",
    "                if v1_type == 'accuracy':\n",
    "                    v1_all.append(1.0)\n",
    "                    \n",
    "    v2_correct = []\n",
    "    v2_all = []\n",
    "    for trial_number in exp_data[subject][v2_experiment]:\n",
    "        trial_data = exp_data[subject][v2_experiment][trial_number]\n",
    "        if trial_data['target_pair_type'] == v2_pair_type and trial_data['target_pair_condition'] == v2_pair_condition:\n",
    "            if trial_data['response_correct'] == 'correct':\n",
    "                if v2_type == 'RT':\n",
    "                    v2_correct.append(float(trial_data['response_time']))\n",
    "                if v2_type == 'accuracy':\n",
    "                    v2_correct.append(1.0)\n",
    "                    v2_all.append(1.0)\n",
    "            else:\n",
    "                if v2_type == 'accuracy':\n",
    "                    v2_all.append(1.0)\n",
    "\n",
    "    if v1_type == 'RT':\n",
    "        if len(v1_correct) == 0:\n",
    "            continue\n",
    "        if len(v2_correct) == 0:\n",
    "            continue \n",
    "        v1_v2_differences.append(np.mean(v1_correct)-np.mean(v2_correct))\n",
    "\n",
    "    if v1_type == 'accuracy':\n",
    "        v1_v2_differences.append(np.sum(v1_correct)/np.sum(v1_all)-np.sum(v2_correct)/np.sum(v2_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.09276129442718099\n",
      "sd: 0.17321720770757362\n",
      "dz: 0.5355200886495134\n",
      "df: 94\n",
      "5.219604171580671\n"
     ]
    }
   ],
   "source": [
    "difference = v1_v2_differences\n",
    "\n",
    "mean = np.mean(difference)\n",
    "\n",
    "SE = np.std(difference) / math.sqrt(len(difference))\n",
    "T  = mean/SE\n",
    "\n",
    "print(\"mean: {}\".format(mean))\n",
    "print(\"sd: {}\".format(np.std(difference)))\n",
    "print(\"dz: {}\".format(np.mean(difference) / np.std(difference)))\n",
    "print(\"df: {}\".format(len(difference)-1))\n",
    "print(T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exp 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the experiment for analysis here\n",
    "exp_ID = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contains log normalized reaction time data \n",
    "filename = \"Exp\" + exp_ID + \"_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather subject labels\n",
    "subject_labels = []\n",
    "\n",
    "with open(filename, mode='r') as csv_file:\n",
    "    csv_reader = csv.DictReader(csv_file)\n",
    "    \n",
    "    for row in csv_reader:\n",
    "        if row['subject'] not in subject_labels:\n",
    "            subject_labels.append(row['subject'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_data = {}\n",
    "\n",
    "current_subjects = subject_labels\n",
    "\n",
    "for subject in current_subjects:\n",
    "    exp_data[subject] = {\"feature_memory\": {}, \"feature_generalization\": {}, \"direct\": {}}\n",
    "\n",
    "    for i in range(12):\n",
    "        exp_data[subject][\"feature_memory\"][i+1] = {}\n",
    "    \n",
    "    for i in range(12):\n",
    "        exp_data[subject][\"feature_generalization\"][i+1] = {}\n",
    "        \n",
    "    for i in range(24):\n",
    "        exp_data[subject][\"direct\"][i+1] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(filename, mode='r') as csv_file:\n",
    "    csv_reader = csv.DictReader(csv_file)\n",
    "    \n",
    "    for row in csv_reader:\n",
    "        \n",
    "        if row['task_type'] == 'feature_memory':\n",
    "                \n",
    "            exp_data[row['subject']][\"feature_memory\"][int(row['trial_number'])] = {\"subject\": row['subject'],\n",
    "                                                                    \"experiment\": exp_ID,\n",
    "                                                                    \"included_in_subsample_analysis\": row['included_in_subsample_analysis'],\n",
    "                                                                    \"task_type\": 'feature_memory',\n",
    "                                                                    \"trial_number\": row['trial_number'],\n",
    "                                                                    \"pair_type\": row['pair_type'],\n",
    "                                                                    \"condition\": row['condition'],\n",
    "                                                                    \"triad_index\": row['triad_index'],\n",
    "                                                                    \"response_correct\": row['response_correct'],\n",
    "                                                                    \"response_time\": row['response_time']}\n",
    "        elif row['task_type'] == 'feature_generalization':\n",
    "            \n",
    "            exp_data[row['subject']][\"feature_generalization\"][int(row['trial_number'])] = {\"subject\": row['subject'],\n",
    "                                                                        \"experiment\": exp_ID,\n",
    "                                                                        \"included_in_subsample_analysis\": row['included_in_subsample_analysis'],\n",
    "                                                                        \"task_type\": 'feature_generalization',\n",
    "                                                                        \"trial_number\": row['trial_number'],\n",
    "                                                                        \"pair_type\": row['pair_type'],\n",
    "                                                                        \"condition\": row['condition'],\n",
    "                                                                        \"triad_index\": row['triad_index'],\n",
    "                                                                        \"response_correct\": row['response_correct'],\n",
    "                                                                        \"response_time\": row['response_time']}\n",
    "            \n",
    "        elif row['task_type'] == 'explicit_direct':\n",
    "            \n",
    "            exp_data[row['subject']][\"direct\"][int(row['trial_number'])] = {\"subject\": row['subject'],\n",
    "                                                                \"experiment\": exp_ID,\n",
    "                                                                \"included_in_subsample_analysis\": row['included_in_subsample_analysis'],\n",
    "                                                                \"task_type\": 'explicit_direct',\n",
    "                                                                \"trial_number\": row['trial_number'],\n",
    "                                                                \"pair_type\": row['pair_type'],\n",
    "                                                                \"condition\": row['condition'],\n",
    "                                                                \"triad_index\": row['triad_index'],\n",
    "                                                                \"response_correct\": row['response_correct'],\n",
    "                                                                \"response_time\": row['response_time']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify two variables to compare\n",
    "\n",
    "# Options: speeded, inference, direct\n",
    "v1_experiment = 'feature_generalization'\n",
    "v2_experiment = 'feature_generalization'\n",
    "\n",
    "v1_pair_type = 'N/A'\n",
    "v2_pair_type = 'N/A'\n",
    "\n",
    "v1_pair_condition = 'intermixed'\n",
    "v2_pair_condition = 'blocked'\n",
    "\n",
    "# Options: RT, accuracy\n",
    "v1_type = 'accuracy'\n",
    "v2_type = 'accuracy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1_v2_differences = []\n",
    "\n",
    "for subject in exp_data:\n",
    "    \n",
    "    v1_correct = []\n",
    "    v1_all = []\n",
    "    for trial_number in exp_data[subject][v1_experiment]:\n",
    "        trial_data = exp_data[subject][v1_experiment][trial_number]\n",
    "        if trial_data['pair_type'] == v1_pair_type and trial_data['condition'] == v1_pair_condition:\n",
    "            if trial_data['response_correct'] == 'correct':\n",
    "                if v1_type == 'RT':\n",
    "                    v1_correct.append(float(trial_data['response_time']))\n",
    "                if v1_type == 'accuracy':\n",
    "                    v1_correct.append(1.0)\n",
    "                    v1_all.append(1.0)\n",
    "            else:\n",
    "                if v1_type == 'accuracy':\n",
    "                    v1_all.append(1.0)\n",
    "                    \n",
    "    v2_correct = []\n",
    "    v2_all = []\n",
    "    for trial_number in exp_data[subject][v2_experiment]:\n",
    "        trial_data = exp_data[subject][v2_experiment][trial_number]\n",
    "        if trial_data['pair_type'] == v2_pair_type and trial_data['condition'] == v2_pair_condition:\n",
    "            if trial_data['response_correct'] == 'correct':\n",
    "                if v2_type == 'RT':\n",
    "                    v2_correct.append(float(trial_data['response_time']))\n",
    "                if v2_type == 'accuracy':\n",
    "                    v2_correct.append(1.0)\n",
    "                    v2_all.append(1.0)\n",
    "            else:\n",
    "                if v2_type == 'accuracy':\n",
    "                    v2_all.append(1.0)\n",
    "\n",
    "    if v1_type == 'RT':\n",
    "        if len(v1_correct) == 0:\n",
    "            continue\n",
    "        if len(v2_correct) == 0:\n",
    "            continue \n",
    "        v1_v2_differences.append(np.mean(v1_correct)-np.mean(v2_correct))\n",
    "\n",
    "    if v1_type == 'accuracy':\n",
    "        v1_v2_differences.append(np.sum(v1_correct)/np.sum(v1_all)-np.sum(v2_correct)/np.sum(v2_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.11006289308176102\n",
      "sd: 0.28583504542534177\n",
      "dz: 0.38505737782426236\n",
      "df: 52\n",
      "2.803260024238837\n"
     ]
    }
   ],
   "source": [
    "difference = v1_v2_differences\n",
    "\n",
    "mean = np.mean(difference)\n",
    "\n",
    "SE = np.std(difference) / math.sqrt(len(difference))\n",
    "T  = mean/SE\n",
    "\n",
    "print(\"mean: {}\".format(mean))\n",
    "print(\"sd: {}\".format(np.std(difference)))\n",
    "print(\"dz: {}\".format(np.mean(difference) / np.std(difference)))\n",
    "print(\"df: {}\".format(len(difference)-1))\n",
    "print(T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exp 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the experiment for analysis here\n",
    "exp_ID = \"3b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contains log normalized reaction time data \n",
    "filename = \"Exp\" + exp_ID + \"_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather subject labels\n",
    "subject_labels = []\n",
    "\n",
    "with open(filename, mode='r') as csv_file:\n",
    "    csv_reader = csv.DictReader(csv_file)\n",
    "    \n",
    "    for row in csv_reader:\n",
    "        if row['subject'] not in subject_labels:\n",
    "            subject_labels.append(row['subject'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_data = {}\n",
    "\n",
    "current_subjects = subject_labels\n",
    "\n",
    "for subject in current_subjects:\n",
    "    \n",
    "    exp_data[subject] = {\"speeded\": {}, \"inference\": {}, \"direct\": {}}\n",
    "\n",
    "    for i in range(48):\n",
    "        exp_data[subject][\"speeded\"][i+1] = {}\n",
    "    \n",
    "    for i in range(12):\n",
    "        exp_data[subject][\"inference\"][i+1] = {}\n",
    "\n",
    "    if exp_ID == \"3b\":\n",
    "        for i in range(24):\n",
    "            exp_data[subject][\"direct\"][i+1] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(filename, mode='r') as csv_file:\n",
    "    csv_reader = csv.DictReader(csv_file)\n",
    "    \n",
    "    for row in csv_reader:\n",
    "        \n",
    "        if row['task_type'] == 'speeded_recognition':\n",
    "                \n",
    "            exp_data[row['subject']][\"speeded\"][int(row['trial_number'])] = {\"subject\": row['subject'],\n",
    "                                                                    \"experiment\": exp_ID,\n",
    "                                                                    \"task_type\": 'speeded_recognition',\n",
    "                                                                    \"trial_number\": row['trial_number'],\n",
    "                                                                    \"target_pair_type\": row['target_pair_type'],\n",
    "                                                                    \"target_pair_condition\": row['target_pair_condition'],\n",
    "                                                                    \"target_triad_index\": row['target_triad_index'],\n",
    "                                                                    \"response_correct\": row['response_correct'],\n",
    "                                                                    \"response_time\": row['response_time']}\n",
    "        elif row['task_type'] == 'explicit_inference':\n",
    "            \n",
    "            exp_data[row['subject']][\"inference\"][int(row['trial_number'])] = {\"subject\": row['subject'],\n",
    "                                                                        \"experiment\": exp_ID,\n",
    "                                                                        \"task_type\": 'explicit_inference',\n",
    "                                                                        \"trial_number\": row['trial_number'],\n",
    "                                                                        \"target_pair_type\": row['target_pair_type'],\n",
    "                                                                        \"target_pair_condition\": row['target_pair_condition'],\n",
    "                                                                        \"target_triad_index\": row['target_triad_index'],\n",
    "                                                                        \"response_correct\": row['response_correct'],\n",
    "                                                                        \"response_time\": row['response_time']}\n",
    "            \n",
    "        elif exp_ID == '3b' and row['task_type'] == 'explicit_direct':\n",
    "            \n",
    "            exp_data[row['subject']][\"direct\"][int(row['trial_number'])] = {\"subject\": row['subject'],\n",
    "                                                                \"experiment\": exp_ID,\n",
    "                                                                \"task_type\": 'explicit_direct',\n",
    "                                                                \"trial_number\": row['trial_number'],\n",
    "                                                                \"target_pair_type\": row['target_pair_type'],\n",
    "                                                                \"target_pair_condition\": row['target_pair_condition'],\n",
    "                                                                \"target_triad_index\": row['target_triad_index'],\n",
    "                                                                \"response_correct\": row['response_correct'],\n",
    "                                                                \"response_time\": row['response_time']}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify two variables to compare\n",
    "\n",
    "# Options: speeded, inference, direct\n",
    "v1_experiment = 'inference'\n",
    "v2_experiment = 'inference'\n",
    "\n",
    "v1_pair_type = 'AC'\n",
    "v2_pair_type = 'AC'\n",
    "\n",
    "v1_pair_condition = 'intermixed'\n",
    "v2_pair_condition = 'blocked'\n",
    "\n",
    "# Options: RT, accuracy\n",
    "v1_type = 'accuracy'\n",
    "v2_type = 'accuracy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1_v2_differences = []\n",
    "\n",
    "for subject in exp_data:\n",
    "    \n",
    "    v1_correct = []\n",
    "    v1_all = []\n",
    "    for trial_number in exp_data[subject][v1_experiment]:\n",
    "        trial_data = exp_data[subject][v1_experiment][trial_number]\n",
    "        if trial_data['target_pair_type'] == v1_pair_type and trial_data['target_pair_condition'] == v1_pair_condition:\n",
    "            if trial_data['response_correct'] == 'correct':\n",
    "                if v1_type == 'RT':\n",
    "                    v1_correct.append(float(trial_data['response_time']))\n",
    "                if v1_type == 'accuracy':\n",
    "                    v1_correct.append(1.0)\n",
    "                    v1_all.append(1.0)\n",
    "            else:\n",
    "                if v1_type == 'accuracy':\n",
    "                    v1_all.append(1.0)\n",
    "                    \n",
    "    v2_correct = []\n",
    "    v2_all = []\n",
    "    for trial_number in exp_data[subject][v2_experiment]:\n",
    "        trial_data = exp_data[subject][v2_experiment][trial_number]\n",
    "        if trial_data['target_pair_type'] == v2_pair_type and trial_data['target_pair_condition'] == v2_pair_condition:\n",
    "            if trial_data['response_correct'] == 'correct':\n",
    "                if v2_type == 'RT':\n",
    "                    v2_correct.append(float(trial_data['response_time']))\n",
    "                if v2_type == 'accuracy':\n",
    "                    v2_correct.append(1.0)\n",
    "                    v2_all.append(1.0)\n",
    "            else:\n",
    "                if v2_type == 'accuracy':\n",
    "                    v2_all.append(1.0)\n",
    "\n",
    "    if v1_type == 'RT':\n",
    "        if len(v1_correct) == 0:\n",
    "            continue\n",
    "        if len(v2_correct) == 0:\n",
    "            continue \n",
    "        v1_v2_differences.append(np.mean(v1_correct)-np.mean(v2_correct))\n",
    "\n",
    "    if v1_type == 'accuracy':\n",
    "        v1_v2_differences.append(np.sum(v1_correct)/np.sum(v1_all)-np.sum(v2_correct)/np.sum(v2_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.1238095238095238\n",
      "sd: 0.35038042169804107\n",
      "dz: 0.353357425650407\n",
      "df: 34\n",
      "2.0904907220984987\n"
     ]
    }
   ],
   "source": [
    "difference = v1_v2_differences\n",
    "\n",
    "mean = np.mean(difference)\n",
    "\n",
    "SE = np.std(difference) / math.sqrt(len(difference))\n",
    "T  = mean/SE\n",
    "\n",
    "print(\"mean: {}\".format(mean))\n",
    "print(\"sd: {}\".format(np.std(difference)))\n",
    "print(\"dz: {}\".format(np.mean(difference) / np.std(difference)))\n",
    "print(\"df: {}\".format(len(difference)-1))\n",
    "print(T)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
